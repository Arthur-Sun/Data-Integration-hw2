INFO main ru.yandex.clickhouse.ClickHouseDriver - Driver registered
INFO main ru.yandex.clickhouse.ClickHouseDriver - Creating connection
INFO main ru.yandex.clickhouse.ClickHouseStatementImpl - Error during connection to ru.yandex.clickhouse.settings.ClickHouseProperties@1b955cac, reporting failure to data source, message: Read timed out
INFO main ru.yandex.clickhouse.ClickHouseStatementImpl - Error sql: select timezone() FORMAT TabSeparatedWithNamesAndTypes;
INFO main org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1000000
	bootstrap.servers = [172.19.102.95:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO main org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Instantiated an idempotent producer.
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1680523128551
INFO main org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1000000
	bootstrap.servers = [172.19.102.95:9093]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO main org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-2] Instantiated an idempotent producer.
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1680523128571
INFO main org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1000000
	bootstrap.servers = [172.19.102.95:9094]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-3
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO main org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-3] Instantiated an idempotent producer.
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1680523128583
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Resetting the last seen epoch of partition test-0 to 52 since the associated topicId changed from null to tiYhXXpVSja3Ys8FpimJWg
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.Metadata - [Producer clientId=producer-3] Cluster ID: YNihvCZiSZqNDkwBznUOLA
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.Metadata - [Producer clientId=producer-2] Cluster ID: YNihvCZiSZqNDkwBznUOLA
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-2] ProducerId set to 77002 with epoch 0
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-3] ProducerId set to 78002 with epoch 0
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: YNihvCZiSZqNDkwBznUOLA
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId set to 76002 with epoch 0
INFO main ru.yandex.clickhouse.ClickHouseDriver - Driver registered
INFO main ru.yandex.clickhouse.ClickHouseDriver - Creating connection
INFO main ru.yandex.clickhouse.ClickHouseStatementImpl - Error during connection to ru.yandex.clickhouse.settings.ClickHouseProperties@6f3c660a, reporting failure to data source, message: Read timed out
INFO main ru.yandex.clickhouse.ClickHouseStatementImpl - Error sql: select timezone() FORMAT TabSeparatedWithNamesAndTypes;
INFO main org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1000000
	bootstrap.servers = [172.19.102.95:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO main org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Instantiated an idempotent producer.
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1680523228540
INFO main org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1000000
	bootstrap.servers = [172.19.102.95:9093]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO main org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-2] Instantiated an idempotent producer.
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1680523228565
INFO main org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1000000
	bootstrap.servers = [172.19.102.95:9094]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-3
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO main org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-3] Instantiated an idempotent producer.
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1680523228594
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Resetting the last seen epoch of partition test-0 to 52 since the associated topicId changed from null to tiYhXXpVSja3Ys8FpimJWg
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.Metadata - [Producer clientId=producer-2] Cluster ID: YNihvCZiSZqNDkwBznUOLA
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.Metadata - [Producer clientId=producer-3] Cluster ID: YNihvCZiSZqNDkwBznUOLA
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-2] ProducerId set to 77003 with epoch 0
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-3] ProducerId set to 78003 with epoch 0
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: YNihvCZiSZqNDkwBznUOLA
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId set to 76003 with epoch 0
INFO main ru.yandex.clickhouse.ClickHouseDriver - Driver registered
INFO main ru.yandex.clickhouse.ClickHouseDriver - Creating connection
INFO main ru.yandex.clickhouse.ClickHouseStatementImpl - Error during connection to ru.yandex.clickhouse.settings.ClickHouseProperties@6dee4f1b, reporting failure to data source, message: Read timed out
INFO main ru.yandex.clickhouse.ClickHouseStatementImpl - Error sql: select timezone() FORMAT TabSeparatedWithNamesAndTypes;
INFO main org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1000000
	bootstrap.servers = [172.19.102.95:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO main org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Instantiated an idempotent producer.
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1680523327751
INFO main org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1000000
	bootstrap.servers = [172.19.102.95:9093]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO main org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-2] Instantiated an idempotent producer.
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1680523327773
INFO main org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1000000
	bootstrap.servers = [172.19.102.95:9094]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-3
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO main org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-3] Instantiated an idempotent producer.
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1680523327783
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Resetting the last seen epoch of partition test-0 to 52 since the associated topicId changed from null to tiYhXXpVSja3Ys8FpimJWg
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.Metadata - [Producer clientId=producer-2] Cluster ID: YNihvCZiSZqNDkwBznUOLA
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.Metadata - [Producer clientId=producer-3] Cluster ID: YNihvCZiSZqNDkwBznUOLA
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-2] ProducerId set to 77004 with epoch 0
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-3] ProducerId set to 78004 with epoch 0
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: YNihvCZiSZqNDkwBznUOLA
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId set to 76004 with epoch 0
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.Metadata - [Producer clientId=producer-2] Resetting the last seen epoch of partition test-0 to 52 since the associated topicId changed from null to tiYhXXpVSja3Ys8FpimJWg
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.Metadata - [Producer clientId=producer-3] Resetting the last seen epoch of partition test-0 to 52 since the associated topicId changed from null to tiYhXXpVSja3Ys8FpimJWg
INFO main ru.yandex.clickhouse.ClickHouseDriver - Driver registered
INFO main ru.yandex.clickhouse.ClickHouseDriver - Creating connection
INFO main ru.yandex.clickhouse.ClickHouseStatementImpl - Error during connection to ru.yandex.clickhouse.settings.ClickHouseProperties@3e681bc, reporting failure to data source, message: Read timed out
INFO main ru.yandex.clickhouse.ClickHouseStatementImpl - Error sql: select timezone() FORMAT TabSeparatedWithNamesAndTypes;
INFO main org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1000000
	bootstrap.servers = [172.19.102.95:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO main org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Instantiated an idempotent producer.
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1680523525619
INFO main org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1000000
	bootstrap.servers = [172.19.102.95:9093]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO main org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-2] Instantiated an idempotent producer.
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1680523525638
INFO main org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1000000
	bootstrap.servers = [172.19.102.95:9094]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-3
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO main org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-3] Instantiated an idempotent producer.
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1680523525650
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Resetting the last seen epoch of partition test-0 to 52 since the associated topicId changed from null to tiYhXXpVSja3Ys8FpimJWg
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.Metadata - [Producer clientId=producer-3] Cluster ID: YNihvCZiSZqNDkwBznUOLA
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.Metadata - [Producer clientId=producer-2] Cluster ID: YNihvCZiSZqNDkwBznUOLA
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-2] ProducerId set to 77005 with epoch 0
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-3] ProducerId set to 78005 with epoch 0
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: YNihvCZiSZqNDkwBznUOLA
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId set to 76005 with epoch 0
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.Metadata - [Producer clientId=producer-2] Resetting the last seen epoch of partition test-0 to 52 since the associated topicId changed from null to tiYhXXpVSja3Ys8FpimJWg
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.Metadata - [Producer clientId=producer-3] Resetting the last seen epoch of partition test-0 to 52 since the associated topicId changed from null to tiYhXXpVSja3Ys8FpimJWg
INFO main ru.yandex.clickhouse.ClickHouseDriver - Driver registered
INFO main ru.yandex.clickhouse.ClickHouseDriver - Creating connection
INFO main org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1000000
	bootstrap.servers = [172.19.102.95:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO main org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Instantiated an idempotent producer.
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1680523669717
INFO main org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1000000
	bootstrap.servers = [172.19.102.95:9093]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO main org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-2] Instantiated an idempotent producer.
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1680523669741
INFO main org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1000000
	bootstrap.servers = [172.19.102.95:9094]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-3
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO main org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-3] Instantiated an idempotent producer.
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1680523669758
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Resetting the last seen epoch of partition test-0 to 52 since the associated topicId changed from null to tiYhXXpVSja3Ys8FpimJWg
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.Metadata - [Producer clientId=producer-3] Cluster ID: YNihvCZiSZqNDkwBznUOLA
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.Metadata - [Producer clientId=producer-2] Cluster ID: YNihvCZiSZqNDkwBznUOLA
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-3] ProducerId set to 78006 with epoch 0
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-2] ProducerId set to 77006 with epoch 0
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: YNihvCZiSZqNDkwBznUOLA
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId set to 76006 with epoch 0
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.Metadata - [Producer clientId=producer-2] Resetting the last seen epoch of partition test-0 to 52 since the associated topicId changed from null to tiYhXXpVSja3Ys8FpimJWg
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.Metadata - [Producer clientId=producer-3] Resetting the last seen epoch of partition test-0 to 52 since the associated topicId changed from null to tiYhXXpVSja3Ys8FpimJWg
INFO main ru.yandex.clickhouse.ClickHouseDriver - Driver registered
INFO main ru.yandex.clickhouse.ClickHouseDriver - Creating connection
INFO main ru.yandex.clickhouse.ClickHouseStatementImpl - Error during connection to ru.yandex.clickhouse.settings.ClickHouseProperties@16f7b4af, reporting failure to data source, message: Read timed out
INFO main ru.yandex.clickhouse.ClickHouseStatementImpl - Error sql: select timezone() FORMAT TabSeparatedWithNamesAndTypes;
INFO main org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1000000
	bootstrap.servers = [172.19.102.95:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO main org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Instantiated an idempotent producer.
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1680524857238
INFO main org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1000000
	bootstrap.servers = [172.19.102.95:9093]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO main org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-2] Instantiated an idempotent producer.
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1680524857282
INFO main org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 1000000
	bootstrap.servers = [172.19.102.95:9094]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-3
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO main org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-3] Instantiated an idempotent producer.
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
INFO main org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1680524857302
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.Metadata - [Producer clientId=producer-2] Cluster ID: YNihvCZiSZqNDkwBznUOLA
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Resetting the last seen epoch of partition test-0 to 52 since the associated topicId changed from null to tiYhXXpVSja3Ys8FpimJWg
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.Metadata - [Producer clientId=producer-3] Cluster ID: YNihvCZiSZqNDkwBznUOLA
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-2] ProducerId set to 77007 with epoch 0
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-3] ProducerId set to 78007 with epoch 0
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: YNihvCZiSZqNDkwBznUOLA
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId set to 76007 with epoch 0
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.Metadata - [Producer clientId=producer-2] Resetting the last seen epoch of partition test-0 to 52 since the associated topicId changed from null to tiYhXXpVSja3Ys8FpimJWg
INFO main ru.yandex.clickhouse.ClickHouseDriver - Driver registered
INFO main ru.yandex.clickhouse.ClickHouseDriver - Creating connection
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.Metadata - [Producer clientId=producer-3] Resetting the last seen epoch of partition test-0 to 52 since the associated topicId changed from null to tiYhXXpVSja3Ys8FpimJWg
INFO main ru.yandex.clickhouse.ClickHouseDriver - Creating connection
INFO main ru.yandex.clickhouse.ClickHouseDriver - Creating connection
INFO main ru.yandex.clickhouse.ClickHouseDriver - Creating connection
INFO main ru.yandex.clickhouse.ClickHouseDriver - Creating connection
INFO main ru.yandex.clickhouse.ClickHouseDriver - Creating connection
INFO main ru.yandex.clickhouse.ClickHouseDriver - Creating connection
INFO main ru.yandex.clickhouse.ClickHouseDriver - Creating connection
INFO main ru.yandex.clickhouse.ClickHouseDriver - Creating connection
INFO main ru.yandex.clickhouse.ClickHouseDriver - Creating connection
INFO main ru.yandex.clickhouse.ClickHouseDriver - Creating connection
INFO main ru.yandex.clickhouse.ClickHouseDriver - Creating connection
INFO main ru.yandex.clickhouse.ClickHouseDriver - Creating connection
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-2] Node -1 disconnected.
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-2] Node 2 disconnected.
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-3] Node 2 disconnected.
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Node 2 disconnected.
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-3] Cancelled in-flight PRODUCE request with correlation id 958 due to node 2 being disconnected (elapsed time since creation: 19130ms, elapsed time since send: 19130ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-3] Cancelled in-flight PRODUCE request with correlation id 959 due to node 2 being disconnected (elapsed time since creation: 19128ms, elapsed time since send: 19128ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-3] Cancelled in-flight PRODUCE request with correlation id 960 due to node 2 being disconnected (elapsed time since creation: 19123ms, elapsed time since send: 19123ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-2] Cancelled in-flight PRODUCE request with correlation id 989 due to node 2 being disconnected (elapsed time since creation: 20578ms, elapsed time since send: 20578ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-3] Cancelled in-flight PRODUCE request with correlation id 961 due to node 2 being disconnected (elapsed time since creation: 19104ms, elapsed time since send: 19104ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-2] Cancelled in-flight PRODUCE request with correlation id 990 due to node 2 being disconnected (elapsed time since creation: 20547ms, elapsed time since send: 20547ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-3] Cancelled in-flight PRODUCE request with correlation id 962 due to node 2 being disconnected (elapsed time since creation: 19102ms, elapsed time since send: 19102ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-2] Cancelled in-flight PRODUCE request with correlation id 991 due to node 2 being disconnected (elapsed time since creation: 20524ms, elapsed time since send: 20524ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-2] Cancelled in-flight PRODUCE request with correlation id 992 due to node 2 being disconnected (elapsed time since creation: 20507ms, elapsed time since send: 20507ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-2] Cancelled in-flight PRODUCE request with correlation id 993 due to node 2 being disconnected (elapsed time since creation: 20484ms, elapsed time since send: 20484ms, request timeout: 30000ms)
WARN kafka-producer-network-thread | producer-3 org.apache.kafka.clients.producer.internals.Sender - [Producer clientId=producer-3] Got error produce response with correlation id 958 on topic-partition test-0, retrying (0 attempts left). Error: NETWORK_EXCEPTION. Error Message: Disconnected from node 2
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Node -1 disconnected.
WARN kafka-producer-network-thread | producer-2 org.apache.kafka.clients.producer.internals.Sender - [Producer clientId=producer-2] Got error produce response with correlation id 989 on topic-partition test-0, retrying (0 attempts left). Error: NETWORK_EXCEPTION. Error Message: Disconnected from node 2
WARN kafka-producer-network-thread | producer-3 org.apache.kafka.clients.producer.internals.Sender - [Producer clientId=producer-3] Received invalid metadata error in produce request on partition test-0 due to org.apache.kafka.common.errors.NetworkException: Disconnected from node 2. Going to request metadata update now
WARN kafka-producer-network-thread | producer-2 org.apache.kafka.clients.producer.internals.Sender - [Producer clientId=producer-2] Received invalid metadata error in produce request on partition test-0 due to org.apache.kafka.common.errors.NetworkException: Disconnected from node 2. Going to request metadata update now
WARN kafka-producer-network-thread | producer-3 org.apache.kafka.clients.producer.internals.Sender - [Producer clientId=producer-3] Got error produce response with correlation id 959 on topic-partition test-0, retrying (0 attempts left). Error: NETWORK_EXCEPTION. Error Message: Disconnected from node 2
WARN kafka-producer-network-thread | producer-2 org.apache.kafka.clients.producer.internals.Sender - [Producer clientId=producer-2] Got error produce response with correlation id 990 on topic-partition test-0, retrying (0 attempts left). Error: NETWORK_EXCEPTION. Error Message: Disconnected from node 2
WARN kafka-producer-network-thread | producer-3 org.apache.kafka.clients.producer.internals.Sender - [Producer clientId=producer-3] Received invalid metadata error in produce request on partition test-0 due to org.apache.kafka.common.errors.NetworkException: Disconnected from node 2. Going to request metadata update now
WARN kafka-producer-network-thread | producer-2 org.apache.kafka.clients.producer.internals.Sender - [Producer clientId=producer-2] Received invalid metadata error in produce request on partition test-0 due to org.apache.kafka.common.errors.NetworkException: Disconnected from node 2. Going to request metadata update now
WARN kafka-producer-network-thread | producer-3 org.apache.kafka.clients.producer.internals.Sender - [Producer clientId=producer-3] Got error produce response with correlation id 960 on topic-partition test-0, retrying (0 attempts left). Error: NETWORK_EXCEPTION. Error Message: Disconnected from node 2
WARN kafka-producer-network-thread | producer-2 org.apache.kafka.clients.producer.internals.Sender - [Producer clientId=producer-2] Got error produce response with correlation id 991 on topic-partition test-0, retrying (0 attempts left). Error: NETWORK_EXCEPTION. Error Message: Disconnected from node 2
WARN kafka-producer-network-thread | producer-3 org.apache.kafka.clients.producer.internals.Sender - [Producer clientId=producer-3] Received invalid metadata error in produce request on partition test-0 due to org.apache.kafka.common.errors.NetworkException: Disconnected from node 2. Going to request metadata update now
WARN kafka-producer-network-thread | producer-2 org.apache.kafka.clients.producer.internals.Sender - [Producer clientId=producer-2] Received invalid metadata error in produce request on partition test-0 due to org.apache.kafka.common.errors.NetworkException: Disconnected from node 2. Going to request metadata update now
WARN kafka-producer-network-thread | producer-3 org.apache.kafka.clients.producer.internals.Sender - [Producer clientId=producer-3] Got error produce response with correlation id 961 on topic-partition test-0, retrying (0 attempts left). Error: NETWORK_EXCEPTION. Error Message: Disconnected from node 2
WARN kafka-producer-network-thread | producer-2 org.apache.kafka.clients.producer.internals.Sender - [Producer clientId=producer-2] Got error produce response with correlation id 992 on topic-partition test-0, retrying (0 attempts left). Error: NETWORK_EXCEPTION. Error Message: Disconnected from node 2
WARN kafka-producer-network-thread | producer-3 org.apache.kafka.clients.producer.internals.Sender - [Producer clientId=producer-3] Received invalid metadata error in produce request on partition test-0 due to org.apache.kafka.common.errors.NetworkException: Disconnected from node 2. Going to request metadata update now
WARN kafka-producer-network-thread | producer-2 org.apache.kafka.clients.producer.internals.Sender - [Producer clientId=producer-2] Received invalid metadata error in produce request on partition test-0 due to org.apache.kafka.common.errors.NetworkException: Disconnected from node 2. Going to request metadata update now
WARN kafka-producer-network-thread | producer-3 org.apache.kafka.clients.producer.internals.Sender - [Producer clientId=producer-3] Got error produce response with correlation id 962 on topic-partition test-0, retrying (0 attempts left). Error: NETWORK_EXCEPTION. Error Message: Disconnected from node 2
WARN kafka-producer-network-thread | producer-2 org.apache.kafka.clients.producer.internals.Sender - [Producer clientId=producer-2] Got error produce response with correlation id 993 on topic-partition test-0, retrying (0 attempts left). Error: NETWORK_EXCEPTION. Error Message: Disconnected from node 2
WARN kafka-producer-network-thread | producer-3 org.apache.kafka.clients.producer.internals.Sender - [Producer clientId=producer-3] Received invalid metadata error in produce request on partition test-0 due to org.apache.kafka.common.errors.NetworkException: Disconnected from node 2. Going to request metadata update now
WARN kafka-producer-network-thread | producer-2 org.apache.kafka.clients.producer.internals.Sender - [Producer clientId=producer-2] Received invalid metadata error in produce request on partition test-0 due to org.apache.kafka.common.errors.NetworkException: Disconnected from node 2. Going to request metadata update now
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-2] Node 1 disconnected.
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-2] Cancelled in-flight API_VERSIONS request with correlation id 994 due to node 1 being disconnected (elapsed time since creation: 10326ms, elapsed time since send: 10326ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-3] Node 0 disconnected.
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-3] Cancelled in-flight METADATA request with correlation id 963 due to node 0 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-3] Node -1 disconnected.
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-3] Node 2 disconnected.
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-2] Node 2 disconnected.
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Node 0 disconnected.
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-2] Cancelled in-flight API_VERSIONS request with correlation id 995 due to node 2 being disconnected (elapsed time since creation: 23508ms, elapsed time since send: 23508ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-3] Cancelled in-flight API_VERSIONS request with correlation id 964 due to node 2 being disconnected (elapsed time since creation: 23508ms, elapsed time since send: 23508ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Cancelled in-flight API_VERSIONS request with correlation id 1588 due to node 0 being disconnected (elapsed time since creation: 23616ms, elapsed time since send: 23616ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-2] Node 2 disconnected.
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Node 1 disconnected.
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-2] Cancelled in-flight API_VERSIONS request with correlation id 996 due to node 2 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Cancelled in-flight API_VERSIONS request with correlation id 1589 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-3] Node 2 disconnected.
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-3] Cancelled in-flight API_VERSIONS request with correlation id 965 due to node 2 being disconnected (elapsed time since creation: 4ms, elapsed time since send: 4ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Node 2 disconnected.
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Cancelled in-flight API_VERSIONS request with correlation id 1590 due to node 2 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-2] Node 0 disconnected.
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-3] Node 1 disconnected.
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-2] Cancelled in-flight API_VERSIONS request with correlation id 997 due to node 0 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-3] Cancelled in-flight API_VERSIONS request with correlation id 966 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-2] Node 2 disconnected.
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-2] Cancelled in-flight API_VERSIONS request with correlation id 998 due to node 2 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-3] Node 0 disconnected.
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Node 0 disconnected.
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-2] Node 1 disconnected.
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Cancelled in-flight API_VERSIONS request with correlation id 1591 due to node 0 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-3] Cancelled in-flight API_VERSIONS request with correlation id 967 due to node 0 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-2] Cancelled in-flight API_VERSIONS request with correlation id 999 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-3] Node 2 disconnected.
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-3] Cancelled in-flight API_VERSIONS request with correlation id 968 due to node 2 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Node 1 disconnected.
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-2] Node 0 disconnected.
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-3] Node 1 disconnected.
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-2] Cancelled in-flight API_VERSIONS request with correlation id 1000 due to node 0 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Cancelled in-flight API_VERSIONS request with correlation id 1592 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-3] Cancelled in-flight API_VERSIONS request with correlation id 969 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-2] Node 1 disconnected.
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Node 2 disconnected.
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-3] Node 0 disconnected.
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Cancelled in-flight API_VERSIONS request with correlation id 1593 due to node 2 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-2] Cancelled in-flight API_VERSIONS request with correlation id 1001 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-3] Cancelled in-flight API_VERSIONS request with correlation id 970 due to node 0 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-3] Node 1 disconnected.
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-3] Cancelled in-flight API_VERSIONS request with correlation id 971 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-2] Node 0 disconnected.
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Node 0 disconnected.
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-2] Cancelled in-flight API_VERSIONS request with correlation id 1002 due to node 0 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Cancelled in-flight API_VERSIONS request with correlation id 1594 due to node 0 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-3] Node 2 disconnected.
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-2] Node 2 disconnected.
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-3] Cancelled in-flight API_VERSIONS request with correlation id 972 due to node 2 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-2] Cancelled in-flight API_VERSIONS request with correlation id 1003 due to node 2 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-2] Node 1 disconnected.
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Node 1 disconnected.
INFO kafka-producer-network-thread | producer-2 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-2] Cancelled in-flight API_VERSIONS request with correlation id 1004 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Cancelled in-flight API_VERSIONS request with correlation id 1595 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-3] Node 0 disconnected.
INFO kafka-producer-network-thread | producer-3 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-3] Cancelled in-flight API_VERSIONS request with correlation id 973 due to node 0 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 30000ms)
INFO kafka-producer-network-thread | producer-1 org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Node 2 disconnected.
