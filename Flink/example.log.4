INFO main KafkaConsumerApp - hello,world.what are you fucking?
INFO main org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.cpu.cores required for local execution is not set, setting it to the maximal possible value.
INFO main org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.task.heap.size required for local execution is not set, setting it to the maximal possible value.
INFO main org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.task.off-heap.size required for local execution is not set, setting it to the maximal possible value.
INFO main org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.network.min required for local execution is not set, setting it to its default value 64 mb.
INFO main org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.network.max required for local execution is not set, setting it to its default value 64 mb.
INFO main org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.managed.size required for local execution is not set, setting it to its default value 128 mb.
INFO main org.apache.flink.runtime.minicluster.MiniCluster - Starting Flink Mini Cluster
INFO main org.apache.flink.runtime.minicluster.MiniCluster - Starting Metrics Registry
INFO main org.apache.flink.runtime.metrics.MetricRegistryImpl - No metrics reporter configured, no metrics will be exposed/reported.
INFO main org.apache.flink.runtime.minicluster.MiniCluster - Starting RPC Service(s)
INFO main org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Trying to start local actor system
INFO flink-akka.actor.default-dispatcher-2 akka.event.slf4j.Slf4jLogger - Slf4jLogger started
INFO main org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Actor system started at akka://flink
INFO main org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Trying to start local actor system
INFO flink-metrics-2 akka.event.slf4j.Slf4jLogger - Slf4jLogger started
INFO main org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Actor system started at akka://flink-metrics
INFO main org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService .
INFO main org.apache.flink.runtime.minicluster.MiniCluster - Starting high-availability services
INFO main org.apache.flink.runtime.blob.BlobServer - Created BLOB server storage directory C:\Users\孙宇鹏\AppData\Local\Temp\blobStore-275455e4-3b93-4b16-a0c6-25f30d80c1ea
INFO main org.apache.flink.runtime.blob.BlobServer - Started BLOB server at 0.0.0.0:51476 - max concurrent requests: 50 - max backlog: 1000
INFO main org.apache.flink.runtime.blob.PermanentBlobCache - Created BLOB cache storage directory C:\Users\孙宇鹏\AppData\Local\Temp\blobStore-927f27dd-eabc-4b3c-aa5f-9e1ae5ce1849
INFO main org.apache.flink.runtime.blob.TransientBlobCache - Created BLOB cache storage directory C:\Users\孙宇鹏\AppData\Local\Temp\blobStore-10600a92-d997-4b12-85f1-b8bc062b2ea2
INFO main org.apache.flink.runtime.minicluster.MiniCluster - Starting 1 TaskManger(s)
INFO main org.apache.flink.runtime.taskexecutor.TaskManagerRunner - Starting TaskManager with ResourceID: f19f25ee-8245-41da-81f4-fafb72e880bd
INFO main org.apache.flink.runtime.taskexecutor.TaskManagerServices - Temporary file directory 'C:\Users\孙宇鹏\AppData\Local\Temp': total 135 GB, usable 15 GB (11.11% usable)
INFO main org.apache.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager uses directory C:\Users\孙宇鹏\AppData\Local\Temp\flink-io-7acf69d1-62cd-4968-b3eb-bad6b25030eb for spill files.
INFO main org.apache.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager uses directory C:\Users\孙宇鹏\AppData\Local\Temp\flink-netty-shuffle-ed2c666d-ccf8-4319-bb17-d6a09e7773cf for spill files.
INFO main org.apache.flink.runtime.io.network.buffer.NetworkBufferPool - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
INFO main org.apache.flink.runtime.io.network.NettyShuffleEnvironment - Starting the network environment and its components.
INFO main org.apache.flink.runtime.taskexecutor.KvStateService - Starting the kvState service and its components.
INFO main org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/rpc/taskmanager_0 .
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService - Start job leader service.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.filecache.FileCache - User file cache uses directory C:\Users\孙宇鹏\AppData\Local\Temp\flink-dist-cache-3233e2c4-5c71-4fcb-b671-e02a38e71d28
INFO main org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint - Starting rest endpoint.
WARN main org.apache.flink.runtime.webmonitor.WebMonitorUtils - Log file environment variable 'log.file' is not set.
WARN main org.apache.flink.runtime.webmonitor.WebMonitorUtils - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'web.log.path'.
INFO main org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint - Rest endpoint listening at localhost:51512
INFO main org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender http://localhost:51512
INFO main org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint - Web frontend listening at http://localhost:51512.
INFO mini-cluster-io-thread-1 org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint - http://localhost:51512 was granted leadership with leaderSessionID=17c3dc79-1f56-4296-b8d4-1074062010cd
INFO mini-cluster-io-thread-1 org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader http://localhost:51512 , session=17c3dc79-1f56-4296-b8d4-1074062010cd
INFO main org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/rpc/resourcemanager_1 .
INFO main org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: DefaultDispatcherRunner
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Starting the resource manager.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: StandaloneResourceManager
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - ResourceManager akka://flink/user/rpc/resourcemanager_1 was granted leadership with fencing token b796769172a9cafa98e2ad726f8f40f7
INFO main org.apache.flink.runtime.minicluster.MiniCluster - Flink Mini Cluster started successfully
INFO mini-cluster-io-thread-2 org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess - Start SessionDispatcherLeaderProcess.
INFO mini-cluster-io-thread-5 org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess - Recover all persisted job graphs.
INFO mini-cluster-io-thread-5 org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess - Successfully recovered 0 persisted job graphs.
INFO mini-cluster-io-thread-6 org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/resourcemanager_1 , session=98e2ad72-6f8f-40f7-b796-769172a9cafa
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.TaskExecutor - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(b796769172a9cafa98e2ad726f8f40f7).
INFO mini-cluster-io-thread-5 org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/rpc/dispatcher_2 .
INFO mini-cluster-io-thread-5 org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/dispatcher_2 , session=397b442e-2a36-4481-97b4-2d14389fc732
INFO flink-akka.actor.default-dispatcher-6 org.apache.flink.runtime.taskexecutor.TaskExecutor - Resolved ResourceManager address, beginning registration
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Registering TaskManager with ResourceID f19f25ee-8245-41da-81f4-fafb72e880bd (akka://flink/user/rpc/taskmanager_0) at ResourceManager
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.TaskExecutor - Successful registration at resource manager akka://flink/user/rpc/resourcemanager_1 under registration id 3a57eee6c410ef5de10fd46e87775016.
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.dispatcher.StandaloneDispatcher - Received JobGraph submission 89fff4542ca0301f94e20ba881e24308 (consumer).
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.dispatcher.StandaloneDispatcher - Submitting job 89fff4542ca0301f94e20ba881e24308 (consumer).
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: JobMasterServiceLeadershipRunner
INFO jobmanager-future-thread-1 org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_3 .
INFO jobmanager-future-thread-1 org.apache.flink.runtime.jobmaster.JobMaster - Initializing job consumer (89fff4542ca0301f94e20ba881e24308).
INFO jobmanager-future-thread-1 org.apache.flink.runtime.jobmaster.JobMaster - Using restart back off time strategy NoRestartBackoffTimeStrategy for consumer (89fff4542ca0301f94e20ba881e24308).
INFO jobmanager-future-thread-1 org.apache.flink.runtime.jobmaster.JobMaster - Running initialization on master for job consumer (89fff4542ca0301f94e20ba881e24308).
INFO jobmanager-future-thread-1 org.apache.flink.runtime.jobmaster.JobMaster - Successfully ran initialization on master in 0 ms.
INFO jobmanager-future-thread-1 org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology - Built 8 pipelined regions in 1 ms
INFO jobmanager-future-thread-1 org.apache.flink.runtime.jobmaster.JobMaster - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@602b98a3
INFO jobmanager-future-thread-1 org.apache.flink.runtime.jobmaster.JobMaster - Checkpoint storage is set to 'jobmanager'
INFO jobmanager-future-thread-1 org.apache.flink.runtime.checkpoint.CheckpointCoordinator - No checkpoint found during restore.
INFO jobmanager-future-thread-1 org.apache.flink.runtime.jobmaster.JobMaster - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@659b7eef for consumer (89fff4542ca0301f94e20ba881e24308).
INFO jobmanager-future-thread-1 org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/jobmanager_3 , session=f68347e6-4566-4717-a451-c2a64b99523a
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.jobmaster.JobMaster - Starting execution of job consumer (89fff4542ca0301f94e20ba881e24308) under job master id a451c2a64b99523af68347e645664717.
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.jobmaster.JobMaster - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.executiongraph.ExecutionGraph - Job consumer (89fff4542ca0301f94e20ba881e24308) switched from state CREATED to RUNNING.
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (58390821cc2a8f183ad2eeeaf8e47fd6) switched from CREATED to SCHEDULED.
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (d424db4be5bb76d7a1fbd4db78c1c33a) switched from CREATED to SCHEDULED.
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (61bec437257134f9d84dc343b6b38b31) switched from CREATED to SCHEDULED.
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (1fd8450d46928b663fbe4bf51c25f736) switched from CREATED to SCHEDULED.
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (e3e9a925b672a55f361f3e5f6f71c40a) switched from CREATED to SCHEDULED.
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (6e810389ba0e0daf2e1633c1465b4f0f) switched from CREATED to SCHEDULED.
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (31c411b2a9c4542006be3984612dfad6) switched from CREATED to SCHEDULED.
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (c8e7069629021630a0cf3de6f750c8f6) switched from CREATED to SCHEDULED.
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.jobmaster.JobMaster - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(b796769172a9cafa98e2ad726f8f40f7)
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.jobmaster.JobMaster - Resolved ResourceManager address, beginning registration
INFO flink-akka.actor.default-dispatcher-5 org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Registering job manager a451c2a64b99523af68347e645664717@akka://flink/user/rpc/jobmanager_3 for job 89fff4542ca0301f94e20ba881e24308.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Registered job manager a451c2a64b99523af68347e645664717@akka://flink/user/rpc/jobmanager_3 for job 89fff4542ca0301f94e20ba881e24308.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.jobmaster.JobMaster - JobManager successfully registered at ResourceManager, leader id: b796769172a9cafa98e2ad726f8f40f7.
INFO flink-akka.actor.default-dispatcher-5 org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager - Received resource requirements from job 89fff4542ca0301f94e20ba881e24308: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=8}]
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 971ad788ea81f1b173520bd8a5ea9d33 for job 89fff4542ca0301f94e20ba881e24308 from resource manager with leader id b796769172a9cafa98e2ad726f8f40f7.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 971ad788ea81f1b173520bd8a5ea9d33.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService - Add job 89fff4542ca0301f94e20ba881e24308 for job leader monitoring.
INFO mini-cluster-io-thread-17 org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService - Try to register at job manager akka://flink/user/rpc/jobmanager_3 with leader id f68347e6-4566-4717-a451-c2a64b99523a.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 2231a5ffc528ffd407d9488fa974c787 for job 89fff4542ca0301f94e20ba881e24308 from resource manager with leader id b796769172a9cafa98e2ad726f8f40f7.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 2231a5ffc528ffd407d9488fa974c787.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 4c472e164dd80ddba287694ce9128f72 for job 89fff4542ca0301f94e20ba881e24308 from resource manager with leader id b796769172a9cafa98e2ad726f8f40f7.
INFO flink-akka.actor.default-dispatcher-5 org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService - Resolved JobManager address, beginning registration
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 4c472e164dd80ddba287694ce9128f72.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 27b2d66a2be227ee666950428960f3de for job 89fff4542ca0301f94e20ba881e24308 from resource manager with leader id b796769172a9cafa98e2ad726f8f40f7.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 27b2d66a2be227ee666950428960f3de.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 83e0e02a9da0696b663afdac6ac959da for job 89fff4542ca0301f94e20ba881e24308 from resource manager with leader id b796769172a9cafa98e2ad726f8f40f7.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 83e0e02a9da0696b663afdac6ac959da.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request fd951b9534b7711a6c50c1ea3c083df6 for job 89fff4542ca0301f94e20ba881e24308 from resource manager with leader id b796769172a9cafa98e2ad726f8f40f7.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for fd951b9534b7711a6c50c1ea3c083df6.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 3705e0ba41c364a524deedee375d26d0 for job 89fff4542ca0301f94e20ba881e24308 from resource manager with leader id b796769172a9cafa98e2ad726f8f40f7.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 3705e0ba41c364a524deedee375d26d0.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 71a7508553fc37465461a5dcfb2eacef for job 89fff4542ca0301f94e20ba881e24308 from resource manager with leader id b796769172a9cafa98e2ad726f8f40f7.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 71a7508553fc37465461a5dcfb2eacef.
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService - Successful registration at job manager akka://flink/user/rpc/jobmanager_3 for job 89fff4542ca0301f94e20ba881e24308.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.TaskExecutor - Establish JobManager connection for job 89fff4542ca0301f94e20ba881e24308.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.TaskExecutor - Offer reserved slots to the leader of job 89fff4542ca0301f94e20ba881e24308.
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (58390821cc2a8f183ad2eeeaf8e47fd6) switched from SCHEDULED to DEPLOYING.
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (attempt #0) with attempt id 58390821cc2a8f183ad2eeeaf8e47fd6 to f19f25ee-8245-41da-81f4-fafb72e880bd @ kubernetes.docker.internal (dataPort=-1) with allocation id 971ad788ea81f1b173520bd8a5ea9d33
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (d424db4be5bb76d7a1fbd4db78c1c33a) switched from SCHEDULED to DEPLOYING.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 971ad788ea81f1b173520bd8a5ea9d33.
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (attempt #0) with attempt id d424db4be5bb76d7a1fbd4db78c1c33a to f19f25ee-8245-41da-81f4-fafb72e880bd @ kubernetes.docker.internal (dataPort=-1) with allocation id 27b2d66a2be227ee666950428960f3de
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (61bec437257134f9d84dc343b6b38b31) switched from SCHEDULED to DEPLOYING.
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (attempt #0) with attempt id 61bec437257134f9d84dc343b6b38b31 to f19f25ee-8245-41da-81f4-fafb72e880bd @ kubernetes.docker.internal (dataPort=-1) with allocation id 83e0e02a9da0696b663afdac6ac959da
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (1fd8450d46928b663fbe4bf51c25f736) switched from SCHEDULED to DEPLOYING.
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (attempt #0) with attempt id 1fd8450d46928b663fbe4bf51c25f736 to f19f25ee-8245-41da-81f4-fafb72e880bd @ kubernetes.docker.internal (dataPort=-1) with allocation id 3705e0ba41c364a524deedee375d26d0
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (e3e9a925b672a55f361f3e5f6f71c40a) switched from SCHEDULED to DEPLOYING.
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (attempt #0) with attempt id e3e9a925b672a55f361f3e5f6f71c40a to f19f25ee-8245-41da-81f4-fafb72e880bd @ kubernetes.docker.internal (dataPort=-1) with allocation id 71a7508553fc37465461a5dcfb2eacef
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (6e810389ba0e0daf2e1633c1465b4f0f) switched from SCHEDULED to DEPLOYING.
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (attempt #0) with attempt id 6e810389ba0e0daf2e1633c1465b4f0f to f19f25ee-8245-41da-81f4-fafb72e880bd @ kubernetes.docker.internal (dataPort=-1) with allocation id 2231a5ffc528ffd407d9488fa974c787
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (31c411b2a9c4542006be3984612dfad6) switched from SCHEDULED to DEPLOYING.
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (attempt #0) with attempt id 31c411b2a9c4542006be3984612dfad6 to f19f25ee-8245-41da-81f4-fafb72e880bd @ kubernetes.docker.internal (dataPort=-1) with allocation id 4c472e164dd80ddba287694ce9128f72
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (c8e7069629021630a0cf3de6f750c8f6) switched from SCHEDULED to DEPLOYING.
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (attempt #0) with attempt id c8e7069629021630a0cf3de6f750c8f6 to f19f25ee-8245-41da-81f4-fafb72e880bd @ kubernetes.docker.internal (dataPort=-1) with allocation id fd951b9534b7711a6c50c1ea3c083df6
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)#0 (58390821cc2a8f183ad2eeeaf8e47fd6), deploy into slot with allocation id 971ad788ea81f1b173520bd8a5ea9d33.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)#0 org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)#0 (58390821cc2a8f183ad2eeeaf8e47fd6) switched from CREATED to DEPLOYING.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 27b2d66a2be227ee666950428960f3de.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)#0 org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)#0 (58390821cc2a8f183ad2eeeaf8e47fd6) [DEPLOYING].
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)#0 (d424db4be5bb76d7a1fbd4db78c1c33a), deploy into slot with allocation id 27b2d66a2be227ee666950428960f3de.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)#0 org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)#0 (d424db4be5bb76d7a1fbd4db78c1c33a) switched from CREATED to DEPLOYING.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 83e0e02a9da0696b663afdac6ac959da.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)#0 org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)#0 (d424db4be5bb76d7a1fbd4db78c1c33a) [DEPLOYING].
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)#0 (61bec437257134f9d84dc343b6b38b31), deploy into slot with allocation id 83e0e02a9da0696b663afdac6ac959da.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 3705e0ba41c364a524deedee375d26d0.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)#0 org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)#0 (61bec437257134f9d84dc343b6b38b31) switched from CREATED to DEPLOYING.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)#0 org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)#0 (61bec437257134f9d84dc343b6b38b31) [DEPLOYING].
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)#0 (1fd8450d46928b663fbe4bf51c25f736), deploy into slot with allocation id 3705e0ba41c364a524deedee375d26d0.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)#0 org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)#0 (1fd8450d46928b663fbe4bf51c25f736) switched from CREATED to DEPLOYING.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 71a7508553fc37465461a5dcfb2eacef.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)#0 org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)#0 (1fd8450d46928b663fbe4bf51c25f736) [DEPLOYING].
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)#0 (e3e9a925b672a55f361f3e5f6f71c40a), deploy into slot with allocation id 71a7508553fc37465461a5dcfb2eacef.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)#0 org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)#0 (e3e9a925b672a55f361f3e5f6f71c40a) switched from CREATED to DEPLOYING.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 2231a5ffc528ffd407d9488fa974c787.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)#0 org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)#0 (e3e9a925b672a55f361f3e5f6f71c40a) [DEPLOYING].
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)#0 (6e810389ba0e0daf2e1633c1465b4f0f), deploy into slot with allocation id 2231a5ffc528ffd407d9488fa974c787.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 4c472e164dd80ddba287694ce9128f72.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)#0 org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)#0 (6e810389ba0e0daf2e1633c1465b4f0f) switched from CREATED to DEPLOYING.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)#0 org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)#0 (6e810389ba0e0daf2e1633c1465b4f0f) [DEPLOYING].
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)#0 (31c411b2a9c4542006be3984612dfad6), deploy into slot with allocation id 4c472e164dd80ddba287694ce9128f72.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot fd951b9534b7711a6c50c1ea3c083df6.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)#0 org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)#0 (31c411b2a9c4542006be3984612dfad6) switched from CREATED to DEPLOYING.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)#0 org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)#0 (31c411b2a9c4542006be3984612dfad6) [DEPLOYING].
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)#0 (c8e7069629021630a0cf3de6f750c8f6), deploy into slot with allocation id fd951b9534b7711a6c50c1ea3c083df6.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)#0 org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@6c3abd66
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)#0 org.apache.flink.streaming.runtime.tasks.StreamTask - Checkpoint storage is set to 'jobmanager'
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)#0 org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@6f3e3cbc
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)#0 org.apache.flink.streaming.runtime.tasks.StreamTask - Checkpoint storage is set to 'jobmanager'
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)#0 org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@5f15f8fa
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)#0 org.apache.flink.streaming.runtime.tasks.StreamTask - Checkpoint storage is set to 'jobmanager'
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 971ad788ea81f1b173520bd8a5ea9d33.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)#0 org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@5e9ad408
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)#0 org.apache.flink.streaming.runtime.tasks.StreamTask - Checkpoint storage is set to 'jobmanager'
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)#0 org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@4bead57e
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)#0 org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@2cfe7fd1
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)#0 org.apache.flink.streaming.runtime.tasks.StreamTask - Checkpoint storage is set to 'jobmanager'
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)#0 org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@353b0211
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)#0 org.apache.flink.streaming.runtime.tasks.StreamTask - Checkpoint storage is set to 'jobmanager'
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 27b2d66a2be227ee666950428960f3de.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 83e0e02a9da0696b663afdac6ac959da.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)#0 org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)#0 (c8e7069629021630a0cf3de6f750c8f6) switched from CREATED to DEPLOYING.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)#0 org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)#0 (c8e7069629021630a0cf3de6f750c8f6) [DEPLOYING].
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 3705e0ba41c364a524deedee375d26d0.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 71a7508553fc37465461a5dcfb2eacef.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)#0 org.apache.flink.streaming.runtime.tasks.StreamTask - Checkpoint storage is set to 'jobmanager'
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 2231a5ffc528ffd407d9488fa974c787.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)#0 org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)#0 (58390821cc2a8f183ad2eeeaf8e47fd6) switched from DEPLOYING to INITIALIZING.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)#0 org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)#0 (1fd8450d46928b663fbe4bf51c25f736) switched from DEPLOYING to INITIALIZING.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)#0 org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)#0 (d424db4be5bb76d7a1fbd4db78c1c33a) switched from DEPLOYING to INITIALIZING.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)#0 org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)#0 (61bec437257134f9d84dc343b6b38b31) switched from DEPLOYING to INITIALIZING.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)#0 org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)#0 (6e810389ba0e0daf2e1633c1465b4f0f) switched from DEPLOYING to INITIALIZING.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)#0 org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@3b274571
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)#0 org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)#0 (e3e9a925b672a55f361f3e5f6f71c40a) switched from DEPLOYING to INITIALIZING.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)#0 org.apache.flink.streaming.runtime.tasks.StreamTask - Checkpoint storage is set to 'jobmanager'
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)#0 org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)#0 (c8e7069629021630a0cf3de6f750c8f6) switched from DEPLOYING to INITIALIZING.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 4c472e164dd80ddba287694ce9128f72.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot fd951b9534b7711a6c50c1ea3c083df6.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)#0 org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)#0 (31c411b2a9c4542006be3984612dfad6) switched from DEPLOYING to INITIALIZING.
INFO flink-akka.actor.default-dispatcher-6 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (58390821cc2a8f183ad2eeeaf8e47fd6) switched from DEPLOYING to INITIALIZING.
INFO flink-akka.actor.default-dispatcher-6 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (1fd8450d46928b663fbe4bf51c25f736) switched from DEPLOYING to INITIALIZING.
INFO flink-akka.actor.default-dispatcher-6 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (d424db4be5bb76d7a1fbd4db78c1c33a) switched from DEPLOYING to INITIALIZING.
INFO flink-akka.actor.default-dispatcher-6 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (61bec437257134f9d84dc343b6b38b31) switched from DEPLOYING to INITIALIZING.
INFO flink-akka.actor.default-dispatcher-6 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (6e810389ba0e0daf2e1633c1465b4f0f) switched from DEPLOYING to INITIALIZING.
INFO flink-akka.actor.default-dispatcher-6 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (e3e9a925b672a55f361f3e5f6f71c40a) switched from DEPLOYING to INITIALIZING.
INFO flink-akka.actor.default-dispatcher-6 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (c8e7069629021630a0cf3de6f750c8f6) switched from DEPLOYING to INITIALIZING.
INFO flink-akka.actor.default-dispatcher-6 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (31c411b2a9c4542006be3984612dfad6) switched from DEPLOYING to INITIALIZING.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)#0 org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 0 has no restore state.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)#0 org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 5 has no restore state.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)#0 org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 2 has no restore state.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)#0 org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 3 has no restore state.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)#0 org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 4 has no restore state.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)#0 org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 6 has no restore state.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)#0 org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 1 has no restore state.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)#0 org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 7 has no restore state.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)#0 org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [172.21.21.16:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)#0 org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [172.21.21.16:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)#0 org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [172.21.21.16:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)#0 org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [172.21.21.16:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)#0 org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [172.21.21.16:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)#0 org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [172.21.21.16:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)#0 org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [172.21.21.16:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)#0 org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [172.21.21.16:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)#0 org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.2
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)#0 org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 73be1e1168f91ee2
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)#0 org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.2
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)#0 org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 73be1e1168f91ee2
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)#0 org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.2
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)#0 org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 73be1e1168f91ee2
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)#0 org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.2
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)#0 org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 73be1e1168f91ee2
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)#0 org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.2
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)#0 org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 73be1e1168f91ee2
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)#0 org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.2
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)#0 org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 73be1e1168f91ee2
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)#0 org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.2
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)#0 org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 73be1e1168f91ee2
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)#0 org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.2
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)#0 org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 73be1e1168f91ee2
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
WARN Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)#0 org.apache.kafka.clients.NetworkClient - Connection to node -1 could not be established. Broker may not be available.
INFO PermanentBlobCache shutdown hook org.apache.flink.runtime.blob.PermanentBlobCache - Shutting down BLOB cache
INFO TaskExecutorLocalStateStoresManager shutdown hook org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager - Shutting down TaskExecutorLocalStateStoresManager.
INFO TransientBlobCache shutdown hook org.apache.flink.runtime.blob.TransientBlobCache - Shutting down BLOB cache
INFO FileCache shutdown hook org.apache.flink.runtime.filecache.FileCache - removed file cache directory C:\Users\孙宇鹏\AppData\Local\Temp\flink-dist-cache-3233e2c4-5c71-4fcb-b671-e02a38e71d28
INFO BlobServer shutdown hook org.apache.flink.runtime.blob.BlobServer - Stopped BLOB server at 0.0.0.0:51476
INFO FileChannelManagerImpl-io shutdown hook org.apache.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager removed spill file directory C:\Users\孙宇鹏\AppData\Local\Temp\flink-io-7acf69d1-62cd-4968-b3eb-bad6b25030eb
INFO FileChannelManagerImpl-netty-shuffle shutdown hook org.apache.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager removed spill file directory C:\Users\孙宇鹏\AppData\Local\Temp\flink-netty-shuffle-ed2c666d-ccf8-4319-bb17-d6a09e7773cf
INFO main KafkaConsumerApp - hello,world.what are you fucking?
INFO main org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.cpu.cores required for local execution is not set, setting it to the maximal possible value.
INFO main org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.task.heap.size required for local execution is not set, setting it to the maximal possible value.
INFO main org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.task.off-heap.size required for local execution is not set, setting it to the maximal possible value.
INFO main org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.network.min required for local execution is not set, setting it to its default value 64 mb.
INFO main org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.network.max required for local execution is not set, setting it to its default value 64 mb.
INFO main org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.managed.size required for local execution is not set, setting it to its default value 128 mb.
INFO main org.apache.flink.runtime.minicluster.MiniCluster - Starting Flink Mini Cluster
INFO main org.apache.flink.runtime.minicluster.MiniCluster - Starting Metrics Registry
INFO main org.apache.flink.runtime.metrics.MetricRegistryImpl - No metrics reporter configured, no metrics will be exposed/reported.
INFO main org.apache.flink.runtime.minicluster.MiniCluster - Starting RPC Service(s)
INFO main org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Trying to start local actor system
INFO flink-akka.actor.default-dispatcher-3 akka.event.slf4j.Slf4jLogger - Slf4jLogger started
INFO main org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Actor system started at akka://flink
INFO main org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Trying to start local actor system
INFO flink-metrics-2 akka.event.slf4j.Slf4jLogger - Slf4jLogger started
INFO main org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Actor system started at akka://flink-metrics
INFO main org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService .
INFO main org.apache.flink.runtime.minicluster.MiniCluster - Starting high-availability services
INFO main org.apache.flink.runtime.blob.BlobServer - Created BLOB server storage directory C:\Users\孙宇鹏\AppData\Local\Temp\blobStore-4e574138-0f06-4624-b47b-6c86954d0924
INFO main org.apache.flink.runtime.blob.BlobServer - Started BLOB server at 0.0.0.0:51617 - max concurrent requests: 50 - max backlog: 1000
INFO main org.apache.flink.runtime.blob.PermanentBlobCache - Created BLOB cache storage directory C:\Users\孙宇鹏\AppData\Local\Temp\blobStore-dccbf14f-e307-4161-a070-aa3163d79edf
INFO main org.apache.flink.runtime.blob.TransientBlobCache - Created BLOB cache storage directory C:\Users\孙宇鹏\AppData\Local\Temp\blobStore-0c967033-ada7-4100-85e2-3142cea5f2b6
INFO main org.apache.flink.runtime.minicluster.MiniCluster - Starting 1 TaskManger(s)
INFO main org.apache.flink.runtime.taskexecutor.TaskManagerRunner - Starting TaskManager with ResourceID: fbdd3763-5c60-491a-9567-29a726ff8205
INFO main org.apache.flink.runtime.taskexecutor.TaskManagerServices - Temporary file directory 'C:\Users\孙宇鹏\AppData\Local\Temp': total 135 GB, usable 15 GB (11.11% usable)
INFO main org.apache.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager uses directory C:\Users\孙宇鹏\AppData\Local\Temp\flink-io-1d5772e0-122c-4f71-8d06-ec6b9b38b01b for spill files.
INFO main org.apache.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager uses directory C:\Users\孙宇鹏\AppData\Local\Temp\flink-netty-shuffle-c2cc864c-0a9b-4dd5-9c47-f684d12dc2f7 for spill files.
INFO main org.apache.flink.runtime.io.network.buffer.NetworkBufferPool - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
INFO main org.apache.flink.runtime.io.network.NettyShuffleEnvironment - Starting the network environment and its components.
INFO main org.apache.flink.runtime.taskexecutor.KvStateService - Starting the kvState service and its components.
INFO main org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/rpc/taskmanager_0 .
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService - Start job leader service.
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.filecache.FileCache - User file cache uses directory C:\Users\孙宇鹏\AppData\Local\Temp\flink-dist-cache-ad4822bc-277c-4ef3-962a-f782f650d24f
INFO main org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint - Starting rest endpoint.
WARN main org.apache.flink.runtime.webmonitor.WebMonitorUtils - Log file environment variable 'log.file' is not set.
WARN main org.apache.flink.runtime.webmonitor.WebMonitorUtils - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'web.log.path'.
INFO main org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint - Rest endpoint listening at localhost:51652
INFO main org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender http://localhost:51652
INFO main org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint - Web frontend listening at http://localhost:51652.
INFO mini-cluster-io-thread-1 org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint - http://localhost:51652 was granted leadership with leaderSessionID=f55d8167-bbe9-4254-b507-5e3ad991e325
INFO mini-cluster-io-thread-1 org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader http://localhost:51652 , session=f55d8167-bbe9-4254-b507-5e3ad991e325
INFO main org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/rpc/resourcemanager_1 .
INFO main org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: DefaultDispatcherRunner
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Starting the resource manager.
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: StandaloneResourceManager
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - ResourceManager akka://flink/user/rpc/resourcemanager_1 was granted leadership with fencing token b03fa14e1e766b0ea427fdf341264d92
INFO main org.apache.flink.runtime.minicluster.MiniCluster - Flink Mini Cluster started successfully
INFO mini-cluster-io-thread-2 org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess - Start SessionDispatcherLeaderProcess.
INFO mini-cluster-io-thread-5 org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess - Recover all persisted job graphs.
INFO mini-cluster-io-thread-5 org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess - Successfully recovered 0 persisted job graphs.
INFO mini-cluster-io-thread-6 org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/resourcemanager_1 , session=a427fdf3-4126-4d92-b03f-a14e1e766b0e
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.taskexecutor.TaskExecutor - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(b03fa14e1e766b0ea427fdf341264d92).
INFO mini-cluster-io-thread-5 org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/rpc/dispatcher_2 .
INFO mini-cluster-io-thread-5 org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/dispatcher_2 , session=da69a3ce-e601-49c9-bd7c-65d959ccab4a
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.TaskExecutor - Resolved ResourceManager address, beginning registration
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Registering TaskManager with ResourceID fbdd3763-5c60-491a-9567-29a726ff8205 (akka://flink/user/rpc/taskmanager_0) at ResourceManager
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.taskexecutor.TaskExecutor - Successful registration at resource manager akka://flink/user/rpc/resourcemanager_1 under registration id dda81e57591461015e312350ddc8674a.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.dispatcher.StandaloneDispatcher - Received JobGraph submission d36994f01e69a25a492dafe36046eec2 (consumer).
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.dispatcher.StandaloneDispatcher - Submitting job d36994f01e69a25a492dafe36046eec2 (consumer).
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: JobMasterServiceLeadershipRunner
INFO jobmanager-future-thread-1 org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_3 .
INFO jobmanager-future-thread-1 org.apache.flink.runtime.jobmaster.JobMaster - Initializing job consumer (d36994f01e69a25a492dafe36046eec2).
INFO jobmanager-future-thread-1 org.apache.flink.runtime.jobmaster.JobMaster - Using restart back off time strategy NoRestartBackoffTimeStrategy for consumer (d36994f01e69a25a492dafe36046eec2).
INFO jobmanager-future-thread-1 org.apache.flink.runtime.jobmaster.JobMaster - Running initialization on master for job consumer (d36994f01e69a25a492dafe36046eec2).
INFO jobmanager-future-thread-1 org.apache.flink.runtime.jobmaster.JobMaster - Successfully ran initialization on master in 0 ms.
INFO jobmanager-future-thread-1 org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology - Built 8 pipelined regions in 1 ms
INFO jobmanager-future-thread-1 org.apache.flink.runtime.jobmaster.JobMaster - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@34d36408
INFO jobmanager-future-thread-1 org.apache.flink.runtime.jobmaster.JobMaster - Checkpoint storage is set to 'jobmanager'
INFO jobmanager-future-thread-1 org.apache.flink.runtime.checkpoint.CheckpointCoordinator - No checkpoint found during restore.
INFO jobmanager-future-thread-1 org.apache.flink.runtime.jobmaster.JobMaster - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@4eedb27 for consumer (d36994f01e69a25a492dafe36046eec2).
INFO jobmanager-future-thread-1 org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/jobmanager_3 , session=d244eeca-653e-4cd2-84be-5f7887016fd1
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.jobmaster.JobMaster - Starting execution of job consumer (d36994f01e69a25a492dafe36046eec2) under job master id 84be5f7887016fd1d244eeca653e4cd2.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.jobmaster.JobMaster - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.executiongraph.ExecutionGraph - Job consumer (d36994f01e69a25a492dafe36046eec2) switched from state CREATED to RUNNING.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (2028c78f2b3b51fb0c5716e81687b870) switched from CREATED to SCHEDULED.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (a49a175d5626e3c997a56db3ca4d8bc3) switched from CREATED to SCHEDULED.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (16b056aecb06ad390a5cc2ca7516379f) switched from CREATED to SCHEDULED.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (88331f4217251894e33e0c0cc691b012) switched from CREATED to SCHEDULED.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (ea5faaa941a54f020d1f17ef6c82eb3c) switched from CREATED to SCHEDULED.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (8dcd934d2d02ff3f74c7e013216b6922) switched from CREATED to SCHEDULED.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (8cf021b54e3b5b8e8e7fe23431c6e4c2) switched from CREATED to SCHEDULED.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (be08aa081eb382edeb9da34437288266) switched from CREATED to SCHEDULED.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.jobmaster.JobMaster - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(b03fa14e1e766b0ea427fdf341264d92)
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.jobmaster.JobMaster - Resolved ResourceManager address, beginning registration
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Registering job manager 84be5f7887016fd1d244eeca653e4cd2@akka://flink/user/rpc/jobmanager_3 for job d36994f01e69a25a492dafe36046eec2.
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Registered job manager 84be5f7887016fd1d244eeca653e4cd2@akka://flink/user/rpc/jobmanager_3 for job d36994f01e69a25a492dafe36046eec2.
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.jobmaster.JobMaster - JobManager successfully registered at ResourceManager, leader id: b03fa14e1e766b0ea427fdf341264d92.
INFO flink-akka.actor.default-dispatcher-3 org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager - Received resource requirements from job d36994f01e69a25a492dafe36046eec2: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=8}]
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 40c308ccbcc69381f701c458e66a08cd for job d36994f01e69a25a492dafe36046eec2 from resource manager with leader id b03fa14e1e766b0ea427fdf341264d92.
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 40c308ccbcc69381f701c458e66a08cd.
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService - Add job d36994f01e69a25a492dafe36046eec2 for job leader monitoring.
INFO mini-cluster-io-thread-17 org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService - Try to register at job manager akka://flink/user/rpc/jobmanager_3 with leader id d244eeca-653e-4cd2-84be-5f7887016fd1.
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 0bc0cd710ff7cddaa410acec58f6a874 for job d36994f01e69a25a492dafe36046eec2 from resource manager with leader id b03fa14e1e766b0ea427fdf341264d92.
INFO flink-akka.actor.default-dispatcher-2 org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService - Resolved JobManager address, beginning registration
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 0bc0cd710ff7cddaa410acec58f6a874.
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 1fd2dc52eb2ded036fc4079110d4f335 for job d36994f01e69a25a492dafe36046eec2 from resource manager with leader id b03fa14e1e766b0ea427fdf341264d92.
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 1fd2dc52eb2ded036fc4079110d4f335.
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 7bddc566a404b442879be2520bcc494b for job d36994f01e69a25a492dafe36046eec2 from resource manager with leader id b03fa14e1e766b0ea427fdf341264d92.
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 7bddc566a404b442879be2520bcc494b.
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request fab125d31cb4779e2b9cc025d23ae1e6 for job d36994f01e69a25a492dafe36046eec2 from resource manager with leader id b03fa14e1e766b0ea427fdf341264d92.
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for fab125d31cb4779e2b9cc025d23ae1e6.
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 9a59def82f31209296ae5196f07dc0f7 for job d36994f01e69a25a492dafe36046eec2 from resource manager with leader id b03fa14e1e766b0ea427fdf341264d92.
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 9a59def82f31209296ae5196f07dc0f7.
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 0bb239b0c7e849fd8b9a93a46781b64b for job d36994f01e69a25a492dafe36046eec2 from resource manager with leader id b03fa14e1e766b0ea427fdf341264d92.
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 0bb239b0c7e849fd8b9a93a46781b64b.
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 63ba79dd72b0a75ba9a578e8187cb9db for job d36994f01e69a25a492dafe36046eec2 from resource manager with leader id b03fa14e1e766b0ea427fdf341264d92.
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 63ba79dd72b0a75ba9a578e8187cb9db.
INFO flink-akka.actor.default-dispatcher-6 org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService - Successful registration at job manager akka://flink/user/rpc/jobmanager_3 for job d36994f01e69a25a492dafe36046eec2.
INFO flink-akka.actor.default-dispatcher-6 org.apache.flink.runtime.taskexecutor.TaskExecutor - Establish JobManager connection for job d36994f01e69a25a492dafe36046eec2.
INFO flink-akka.actor.default-dispatcher-6 org.apache.flink.runtime.taskexecutor.TaskExecutor - Offer reserved slots to the leader of job d36994f01e69a25a492dafe36046eec2.
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (2028c78f2b3b51fb0c5716e81687b870) switched from SCHEDULED to DEPLOYING.
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (attempt #0) with attempt id 2028c78f2b3b51fb0c5716e81687b870 to fbdd3763-5c60-491a-9567-29a726ff8205 @ kubernetes.docker.internal (dataPort=-1) with allocation id 9a59def82f31209296ae5196f07dc0f7
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (a49a175d5626e3c997a56db3ca4d8bc3) switched from SCHEDULED to DEPLOYING.
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (attempt #0) with attempt id a49a175d5626e3c997a56db3ca4d8bc3 to fbdd3763-5c60-491a-9567-29a726ff8205 @ kubernetes.docker.internal (dataPort=-1) with allocation id 0bc0cd710ff7cddaa410acec58f6a874
INFO flink-akka.actor.default-dispatcher-6 org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 9a59def82f31209296ae5196f07dc0f7.
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (16b056aecb06ad390a5cc2ca7516379f) switched from SCHEDULED to DEPLOYING.
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (attempt #0) with attempt id 16b056aecb06ad390a5cc2ca7516379f to fbdd3763-5c60-491a-9567-29a726ff8205 @ kubernetes.docker.internal (dataPort=-1) with allocation id 7bddc566a404b442879be2520bcc494b
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (88331f4217251894e33e0c0cc691b012) switched from SCHEDULED to DEPLOYING.
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (attempt #0) with attempt id 88331f4217251894e33e0c0cc691b012 to fbdd3763-5c60-491a-9567-29a726ff8205 @ kubernetes.docker.internal (dataPort=-1) with allocation id 0bb239b0c7e849fd8b9a93a46781b64b
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (ea5faaa941a54f020d1f17ef6c82eb3c) switched from SCHEDULED to DEPLOYING.
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (attempt #0) with attempt id ea5faaa941a54f020d1f17ef6c82eb3c to fbdd3763-5c60-491a-9567-29a726ff8205 @ kubernetes.docker.internal (dataPort=-1) with allocation id 40c308ccbcc69381f701c458e66a08cd
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (8dcd934d2d02ff3f74c7e013216b6922) switched from SCHEDULED to DEPLOYING.
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (attempt #0) with attempt id 8dcd934d2d02ff3f74c7e013216b6922 to fbdd3763-5c60-491a-9567-29a726ff8205 @ kubernetes.docker.internal (dataPort=-1) with allocation id 63ba79dd72b0a75ba9a578e8187cb9db
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (8cf021b54e3b5b8e8e7fe23431c6e4c2) switched from SCHEDULED to DEPLOYING.
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (attempt #0) with attempt id 8cf021b54e3b5b8e8e7fe23431c6e4c2 to fbdd3763-5c60-491a-9567-29a726ff8205 @ kubernetes.docker.internal (dataPort=-1) with allocation id 1fd2dc52eb2ded036fc4079110d4f335
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (be08aa081eb382edeb9da34437288266) switched from SCHEDULED to DEPLOYING.
INFO flink-akka.actor.default-dispatcher-4 org.apache.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (attempt #0) with attempt id be08aa081eb382edeb9da34437288266 to fbdd3763-5c60-491a-9567-29a726ff8205 @ kubernetes.docker.internal (dataPort=-1) with allocation id fab125d31cb4779e2b9cc025d23ae1e6
INFO flink-akka.actor.default-dispatcher-6 org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)#0 (2028c78f2b3b51fb0c5716e81687b870), deploy into slot with allocation id 9a59def82f31209296ae5196f07dc0f7.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)#0 org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)#0 (2028c78f2b3b51fb0c5716e81687b870) switched from CREATED to DEPLOYING.
INFO flink-akka.actor.default-dispatcher-6 org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 0bc0cd710ff7cddaa410acec58f6a874.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)#0 org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)#0 (2028c78f2b3b51fb0c5716e81687b870) [DEPLOYING].
INFO flink-akka.actor.default-dispatcher-6 org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)#0 (a49a175d5626e3c997a56db3ca4d8bc3), deploy into slot with allocation id 0bc0cd710ff7cddaa410acec58f6a874.
INFO flink-akka.actor.default-dispatcher-6 org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 7bddc566a404b442879be2520bcc494b.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)#0 org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)#0 (a49a175d5626e3c997a56db3ca4d8bc3) switched from CREATED to DEPLOYING.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)#0 org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)#0 (a49a175d5626e3c997a56db3ca4d8bc3) [DEPLOYING].
INFO flink-akka.actor.default-dispatcher-6 org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)#0 (16b056aecb06ad390a5cc2ca7516379f), deploy into slot with allocation id 7bddc566a404b442879be2520bcc494b.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)#0 org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)#0 (16b056aecb06ad390a5cc2ca7516379f) switched from CREATED to DEPLOYING.
INFO flink-akka.actor.default-dispatcher-6 org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 0bb239b0c7e849fd8b9a93a46781b64b.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)#0 org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)#0 (16b056aecb06ad390a5cc2ca7516379f) [DEPLOYING].
INFO flink-akka.actor.default-dispatcher-6 org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)#0 (88331f4217251894e33e0c0cc691b012), deploy into slot with allocation id 0bb239b0c7e849fd8b9a93a46781b64b.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)#0 org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)#0 (88331f4217251894e33e0c0cc691b012) switched from CREATED to DEPLOYING.
INFO flink-akka.actor.default-dispatcher-6 org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 40c308ccbcc69381f701c458e66a08cd.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)#0 org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)#0 (88331f4217251894e33e0c0cc691b012) [DEPLOYING].
INFO flink-akka.actor.default-dispatcher-6 org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)#0 (ea5faaa941a54f020d1f17ef6c82eb3c), deploy into slot with allocation id 40c308ccbcc69381f701c458e66a08cd.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)#0 org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)#0 (ea5faaa941a54f020d1f17ef6c82eb3c) switched from CREATED to DEPLOYING.
INFO flink-akka.actor.default-dispatcher-6 org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 63ba79dd72b0a75ba9a578e8187cb9db.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)#0 org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)#0 (ea5faaa941a54f020d1f17ef6c82eb3c) [DEPLOYING].
INFO flink-akka.actor.default-dispatcher-6 org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)#0 (8dcd934d2d02ff3f74c7e013216b6922), deploy into slot with allocation id 63ba79dd72b0a75ba9a578e8187cb9db.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)#0 org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)#0 (8dcd934d2d02ff3f74c7e013216b6922) switched from CREATED to DEPLOYING.
INFO flink-akka.actor.default-dispatcher-6 org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 1fd2dc52eb2ded036fc4079110d4f335.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)#0 org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)#0 (8dcd934d2d02ff3f74c7e013216b6922) [DEPLOYING].
INFO flink-akka.actor.default-dispatcher-6 org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)#0 (8cf021b54e3b5b8e8e7fe23431c6e4c2), deploy into slot with allocation id 1fd2dc52eb2ded036fc4079110d4f335.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)#0 org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@60b3570
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)#0 org.apache.flink.streaming.runtime.tasks.StreamTask - Checkpoint storage is set to 'jobmanager'
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)#0 org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)#0 (8cf021b54e3b5b8e8e7fe23431c6e4c2) switched from CREATED to DEPLOYING.
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)#0 org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@776854f4
INFO Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)#0 org.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@62c0f67b
